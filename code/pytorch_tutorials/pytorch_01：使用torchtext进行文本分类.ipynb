{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch 01：使用torchtext进行文本分类.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNu8mKCoKIaoRBH2tcsPezM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chongzicbo/nlp-ml-dl-notes/blob/master/pytorch_tutorials/pytorch_01%EF%BC%9A%E4%BD%BF%E7%94%A8torchtext%E8%BF%9B%E8%A1%8C%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svc9Mjdlz97x",
        "colab_type": "text"
      },
      "source": [
        "导入所需的库"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxwxThsj1ze9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install torchtext==0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iwfbOzr0dh9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchtext\n",
        "from torchtext.datasets import text_classification\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnsM36Iq0zLg",
        "colab_type": "code",
        "outputId": "028f54e8-bcad-4099-e502-33a158296bd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torchtext.__version__,torch.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('0.5.0', '1.4.0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXGwkjjl1epu",
        "colab_type": "text"
      },
      "source": [
        "基本参数配置"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIf8DFj-2Zb4",
        "colab_type": "code",
        "outputId": "6ab336d7-15e3-40ad-ed40-ac73b2f9c5c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "NGRAMS=2\n",
        "if not os.path.isdir('./data'):\n",
        "  os.mkdir('./data')\n",
        "\n",
        "train_dataset,test_dataset=text_classification.DATASETS['AG_NEWS'](root='./data',ngrams=NGRAMS,vocab=None) #ngrams参数设置将文本进行分割\n",
        "\n",
        "BATCH_SIZE=16\n",
        "device=torch.device('cuda' if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "120000lines [00:08, 13373.81lines/s]\n",
            "120000lines [00:18, 6661.00lines/s]\n",
            "7600lines [00:01, 6724.91lines/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD_2O8Pm3WhI",
        "colab_type": "text"
      },
      "source": [
        "定义模型网络:Embedding层+全连接层\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDgQ2NhP3y66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class TextSentiment(nn.Module):\n",
        "  def __init__(self,vocab_size,embed_dim,num_class):\n",
        "    super().__init__()\n",
        "    self.embedding=nn.EmbeddingBag(vocab_size,embed_dim,sparse=True)\n",
        "    self.fc=nn.Linear(embed_dim,num_class)\n",
        "    self.init_weights()\n",
        "\n",
        "  def init_weights(self):\n",
        "    #初始化权重参数\n",
        "    initrange=0.5\n",
        "    self.embedding.weight.data.uniform_(-initrange,initrange)\n",
        "    self.fc.weight.data.uniform_(-initrange,initrange)\n",
        "    self.fc.bias.data.zero_()\n",
        "\n",
        "  def forward(self,text,offsets):\n",
        "    #前向传播\n",
        "    embedded=self.embedding(text,offsets)\n",
        "    return self.fc(embedded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hahNsHaNZ9i7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOCAB_SIZE=len(train_dataset.get_vocab())\n",
        "EMBED_DIM=32 #词向量维度\n",
        "NUM_CLASS=len(train_dataset.get_labels())\n",
        "model=TextSentiment(VOCAB_SIZE,EMBED_DIM,NUM_CLASS).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpNwcJLZeeRd",
        "colab_type": "text"
      },
      "source": [
        "构建一个生成批量数据的函数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T-YUDcMahLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_batch(batch):\n",
        "  label=torch.tensor([entry[0] for entry in batch])\n",
        "  text=[entry[1] for entry in batch]\n",
        "  offsets=[0]+[len(entry) for entry in text]\n",
        "  offsets=torch.tensor(offsets[:-1]).cumsum(dim=0) #偏移量计算\n",
        "  text=torch.cat(text)\n",
        "  return text,offsets,label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMrehpsddm2F",
        "colab_type": "code",
        "outputId": "c5322695-8347-4309-ddf8-ef93ea86dcc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "torch.Tensor([0.0,1.0,2.0,3.0,4.0,5.0][:-1]).cumsum(dim=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.,  1.,  3.,  6., 10.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxXR6S35duXS",
        "colab_type": "text"
      },
      "source": [
        "定义模型训练和评估函数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFFQOhMyeuNJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3TlPZJ2e2I1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_func(sub_train_,optimizer,criterion):\n",
        "  train_loss=0 #训练损失\n",
        "  train_acc=0 #训练精度\n",
        "\n",
        "  data=DataLoader(sub_train_,batch_size=BATCH_SIZE,shuffle=True,collate_fn=generate_batch)\n",
        "  for i,(text,offsets,cls) in enumerate(data):\n",
        "    optimizer.zero_grad()\n",
        "    text,offsets,cls=text.to(device),offsets.to(device),cls.to(device)\n",
        "    output=model(text,offsets)\n",
        "    loss=criterion(output,cls) #计算损失\n",
        "    train_loss+=loss.item() #训练损失叠加\n",
        "    loss.backward() #反向传播\n",
        "    optimizer.step() #梯度更新\n",
        "    train_acc+=(output.argmax(1)==cls).sum().item()\n",
        "  scheduler.step() #更新学习率\n",
        "\n",
        "  return train_loss/len(sub_train_),train_acc/len(sub_train_)\n",
        "\n",
        "\n",
        "def test(data_,criterion):\n",
        "  loss=0\n",
        "  acc=0\n",
        "  data=DataLoader(data_,batch_size=BATCH_SIZE,collate_fn=generate_batch)\n",
        "  for text,offsets,cls in data:\n",
        "    text,offsets,cls=text.to(device),offsets.to(device),cls.to(device)\n",
        "    with torch.no_grad():\n",
        "      output=model(text,offsets)\n",
        "      loss=criterion(output,cls)\n",
        "      loss+=loss.item()\n",
        "      acc+=(output.argmax(1)==cls).sum().item()\n",
        "\n",
        "  return loss/len(data_),acc/len(data_)    \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd1t5Cle8mhF",
        "colab_type": "code",
        "outputId": "31313783-659e-455b-dd78-a959d9921434",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "import time\n",
        "from torch.utils.data.dataset import random_split\n",
        "N_EPOCHS=5\n",
        "min_valid_loss=float('inf')\n",
        "criterion=torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=4.0)\n",
        "scheduler=torch.optim.lr_scheduler.StepLR(optimizer,1,gamma=0.9)\n",
        "\n",
        "train_len=int(len(train_dataset)*0.95)\n",
        "sub_train_,sub_valid_=random_split(train_dataset,[train_len,len(train_dataset)-train_len])\n",
        "for epoch in range(N_EPOCHS):\n",
        "  start_time=time.time()\n",
        "  train_loss,train_acc=train_func(sub_train_,optimizer=optimizer,criterion=criterion)\n",
        "  valid_loss,valid_acc=test(sub_valid_,criterion)\n",
        "  secs=int(time.time()-start_time)\n",
        "  mins=secs/60\n",
        "  secs=secs%60\n",
        "  print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
        "  print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
        "  print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1  | time in 0 minutes, 27 seconds\n",
            "\tLoss: 0.0023(train)\t|\tAcc: 98.9%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 98.2%(valid)\n",
            "Epoch: 2  | time in 0 minutes, 27 seconds\n",
            "\tLoss: 0.0017(train)\t|\tAcc: 99.2%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 98.7%(valid)\n",
            "Epoch: 3  | time in 0 minutes, 27 seconds\n",
            "\tLoss: 0.0011(train)\t|\tAcc: 99.6%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 98.5%(valid)\n",
            "Epoch: 4  | time in 0 minutes, 27 seconds\n",
            "\tLoss: 0.0008(train)\t|\tAcc: 99.7%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 98.7%(valid)\n",
            "Epoch: 5  | time in 0 minutes, 27 seconds\n",
            "\tLoss: 0.0005(train)\t|\tAcc: 99.8%(train)\n",
            "\tLoss: 0.0000(valid)\t|\tAcc: 98.9%(valid)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Dy7pgNaCBWd",
        "colab_type": "text"
      },
      "source": [
        "使用测试数据集评估模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuTHq4trCMu0",
        "colab_type": "code",
        "outputId": "a76a1751-fb82-4275-8633-e66155a82751",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('使用测试数据集进行测试-----')\n",
        "test_loss,test_acc=test(test_dataset,criterion)\n",
        "print(f'\\tLoss: {test_loss:.4f}(test)\\t|\\tAcc: {test_acc * 100:.1f}%(test)')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "使用测试数据集进行测试-----\n",
            "\tLoss: 0.0004(test)\t|\tAcc: 89.1%(test)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GdSXspK-QgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_loader=DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True,collate_fn=generate_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvQ6Wy2g-T9w",
        "colab_type": "code",
        "outputId": "ff1f14c9-13ea-4f9a-86be-af7900b74b52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "for x,y,z in data_loader:\n",
        "  print(x)\n",
        "  print(y)\n",
        "  print(z)\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([4088, 7956, 1290,  ...,  152,  243, 6634])\n",
            "tensor([   0,   55,  132,  217,  268,  337,  442,  507,  610,  727,  810,  919,\n",
            "        1020, 1079, 1176, 1259])\n",
            "tensor([2, 2, 1, 3, 3, 2, 1, 3, 1, 3, 3, 2, 1, 1, 2, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnDnSaGH-aA8",
        "colab_type": "code",
        "outputId": "290a62ad-f795-47d8-bec4-3a5ebba3ea0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import re\n",
        "from torchtext.data.utils import ngrams_iterator\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "ag_news_label = {1 : \"World\",\n",
        "                 2 : \"Sports\",\n",
        "                 3 : \"Business\",\n",
        "                 4 : \"Sci/Tec\"}\n",
        "\n",
        "def predict(text,model,vocab,ngram):\n",
        "  tokenizer=get_tokenizer('basic_english')\n",
        "  with torch.no_grad():\n",
        "    text=torch.tensor([vocab[token] for token in ngrams_iterator(tokenizer(text),ngram)])\n",
        "    output=model(text,torch.tensor([0]))\n",
        "    return output.argmax(1).item()+1\n",
        "\n",
        "ex_text_str = \"MEMPHIS, Tenn. – Four days ago, Jon Rahm was \\\n",
        "    enduring the season’s worst weather conditions on Sunday at The \\\n",
        "    Open on his way to a closing 75 at Royal Portrush, which \\\n",
        "    considering the wind and the rain was a respectable showing. \\\n",
        "    Thursday’s first round at the WGC-FedEx St. Jude Invitational \\\n",
        "    was another story. With temperatures in the mid-80s and hardly any \\\n",
        "    wind, the Spaniard was 13 strokes better in a flawless round. \\\n",
        "    Thanks to his best putting performance on the PGA Tour, Rahm \\\n",
        "    finished with an 8-under 62 for a three-stroke lead, which \\\n",
        "    was even more impressive considering he’d never played the \\\n",
        "    front nine at TPC Southwind.\"\n",
        "\n",
        "vocab = train_dataset.get_vocab()\n",
        "model = model.to(\"cpu\")\n",
        "\n",
        "print(\"This is a %s news\" %ag_news_label[predict(ex_text_str, model, vocab, 2)])    \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is a Sports news\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXgVRfiZ-lbQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}