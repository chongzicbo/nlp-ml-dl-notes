朴素贝叶斯(naive Bayes)法是基于贝叶斯定理和特征条件独立假设的分类方法。对于给定的训练数据集，首先基于特征条件独立假设学习输入/输出的联合概率；然后基于此模型，对给定的输入$x$，利用贝叶斯定理求出后验概率最大的输出$y$。

# **1.朴素贝叶斯法的学习与分类**

## **1.1 学习**

给定输入集合$X$，输出集合$Y$，$P(X,Y)$是输入$X$和输出$Y$的联合概率分布。训练数据集：
$$
T=\{(x_1,y_1),(x_2,y_2),\ldots,(x_N,y_N)\}
$$


由$P(X,Y)$独立同分布产生。

朴素贝叶斯法通过训练数据集学习联合概率分布$P(X,Y)$。具体就是学习先验概率分布:
$$
P(Y=c_k),k=1,2,3,\ldots,K
$$


和条件概率分布：
$$
P(X=x|Y=c_k)=P(X^{(1)}=x^{(1)},\ldots,X^{(n)}=x^{(n)}|Y=c_k,k=1,2,\ldots,K)
$$
然后通过先验概率分布和条件概率分布学习到联合概率分布$P(X,Y)$。

条件概率分布$P(X=x|Y=C_k)$的参数数量是指数量级的，对其进行估计实际上并不可行。假设$x^{(j)}$可取值有$S_j$个,j=1,2,...,n,$Y$可取值有$K$个，那么参数数量为：

$$
K\prod_{j=1}^{n}S_j
$$
朴素贝叶斯法对条件概率分布作了条件独立性假设，即：

$$
P(X=x|Y=c_k)=P(X^{(1)}
=x^{(1)},\ldots,X^{(n)}
=x^{(n)}|Y=c_k) \\
=\prod _{j=1}^n P(X^{(j)}
=x^{(j)}|Y=c_k)
$$
也就是说用于分类的特征在类确定的条件下是条件独立的，这一假设虽然会使得分类变得简单，但会牺牲一定的分类准确率。



## **1.2 分类**

朴素贝叶斯法在分类时，对给定的输入$x$，通过学习到的模型计算后验概率分布$P(Y=C_k|X=x)$，将后验概率最大的类作为$x$的类输出，后验概率通过贝叶斯定理计算得出：

![img](https://gitee.com/chengbo123/images/raw/master/wps_clip_image-29867.png)

将（5）式代入4.4有：

![img](https://gitee.com/chengbo123/images/raw/master/wps_clip_image-30044.png)

于是朴素贝叶斯分类器可表示为：

![img](https://gitee.com/chengbo123/images/raw/master/wps_clip_image-30083.png)

上式中，分母对所有Ck都是相同的，所以：

![img](https://gitee.com/chengbo123/images/raw/master/wps_clip_image-30135.png)

## **1.3 后验概率最大化**

朴素贝叶斯法将实例分到后验概率最大的类中，**等价于期望风险最小化**。假设选择0-1损失函数：

![img](https://gitee.com/chengbo123/images/raw/master/wps_clip_image-30387.png)

式中f(X)是分类决策函数。这时，期望风险函数为：

![img](https://gitee.com/chengbo123/images/raw/master/wps_clip_image-30416.png)

该期望是对联合分布$P(X,Y)$取的，由此取条件期望：

![img](https://gitee.com/chengbo123/images/raw/master/wps_clip_image-30501.png)

对X=x逐个极小化可以使得期望风险最小化：

![img](https://gitee.com/chengbo123/images/raw/master/wps_clip_image-30550.png)

从上式可知，根据期望风险最小化准则可得后验概率最大化准则：

![img](https://gitee.com/chengbo123/images/raw/master/wps_clip_image-30582.png)

根据期望风险最小化推导后验概率最大化可参考这篇文章：[朴素贝叶斯(NBM)之后验概率最大化的含义 | 统计学习方法](https://zhuanlan.zhihu.com/p/215897132)

# **2.朴素贝叶斯法的参数估计**

## **2.1 极大似然估计**

朴素贝叶斯法就是估计$P(Y=C_k)$和$P(X^{(j)}|Y=C_k)$，从而求得联合概率分布$P(X,Y)$,然后计算后验概率。先验概率$P(Y=C_k)$的极大似然估计是：

![img](https://gitee.com/chengbo123/images/raw/master/wps_clip_image-30994.png)

设第$j$个特征$x^{(j)}$可能取值的集合为

![img](https://gitee.com/chengbo123/images/raw/master/wps_clip_image-31078.png)

则条件概率$P(X^{(j)}|Y=C_k)$的极大似然估计是：

![img](https://gitee.com/chengbo123/images/raw/master/wps_clip_image-31320.png)

式中，$x^{(j)}_i$是第$i$个样本的第$j$个特征；$a_{ij}$是第$j$个特征可能取得第$l$个值；$I$为指示函数。



## **2.2 贝叶斯估计**

条件概率得贝叶斯估计是：

![img](https://gitee.com/chengbo123/images/raw/master/wps_clip_image-31529.png)

式中$λ≥0$，等价于在特征得各个取值得频数上赋予一个整数$λ>0,λ=0$时就是极大似然估计，λ=1时称为拉普拉斯平滑。对于任何$l=1,2,...,S_j,k=1,2,...K$,有：

![img](https://gitee.com/chengbo123/images/raw/master/wps_clip_image-31562.png)

同样先验概率得贝叶斯估计为：

![img](https://gitee.com/chengbo123/images/raw/master/wps_clip_image-31598.png)

