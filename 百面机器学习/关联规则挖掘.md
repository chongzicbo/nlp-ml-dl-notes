# [数据挖掘系列（1）关联规则挖掘基本概念与Aprior算法](https://www.cnblogs.com/fengfenggirl/p/associate_apriori.html)

# [数据挖掘系列（2）--关联规则FpGrowth算法](https://www.cnblogs.com/fengfenggirl/p/associate_fpgowth.html)

# [深入机器学习系列之：关联规则挖掘基础篇](https://cloud.tencent.com/developer/article/1540473)



# 1.关联规则基本概念

基本定义：关联规则就是有关联的规则，形式是这样定义的：*两个不相交的非空集合X、Y，如果有X-->Y，就说X-->Y是一条关联规则*。举个例子，在上面的表中，我们发现购买啤酒就一定会购买尿布，{啤酒}-->{尿布}就是一条关联规则。关联规则的强度用支持度(support)和自信度(confidence)来描述，

支持度的定义：*support(X-->Y) = |X交Y|/N=集合X与集合Y中的项\*在一条记录中\*同时出现的次数/数据记录的个数*。例如：support({啤酒}-->{尿布}) = 啤酒和尿布同时出现的次数/数据记录数 = 3/5=60%。

自信度的定义：*confidence(X-->Y) = |\*X交\*Y|/|X| = 集合X与集合Y中的项在一条记录中同时出现的次数/集合X出现的个数* 。例如：confidence({啤酒}-->{尿布}) = 啤酒和尿布同时出现的次数/啤酒出现的次数=3/3=100%;confidence({尿布}-->{啤酒}) = 啤酒和尿布同时出现的次数/尿布出现的次数 = 3/4 = 75%。

这里定义的支持度和自信度都是相对的支持度和自信度，不是绝对支持度，绝对支持度abs_support = 数据记录数N*support。

支持度和自信度越高，说明规则越强，关联规则挖掘就是挖掘出满足一定强度的规则。

# **2、关联规则挖掘的定义与步骤**

　　关联规则挖掘的定义：*给定一个交易数据集T，找出其中所有支持度support >= min_support、自信度confidence >= min_confidence的关联规则。*

　　有一个简单而粗鲁的方法可以找出所需要的规则，那就是穷举项集的所有组合，并测试每个组合是否满足条件，一个元素个数为n的项集的组合个数为2^n-1(除去空集)，所需要的时间复杂度明显为O(2^N)，对于普通的超市，其商品的项集数也在1万以上，用指数时间复杂度的算法不能在可接受的时间内解决问题。怎样快速挖出满足条件的关联规则是关联挖掘的需要解决的主要问题。

　　仔细想一下，我们会发现对于{啤酒-->尿布}，{尿布-->啤酒}这两个规则的支持度实际上只需要计算{尿布，啤酒}的支持度，即它们交集的支持度。于是我们把关联规则挖掘分两步进行：

　　**1）生成频繁项集**

　　这一阶段找出所有满足最小支持度的项集，找出的这些项集称为频繁项集。

　　**2）生成规则**

　　在上一步产生的频繁项集的基础上生成满足最小自信度的规则，产生的规则称为强规则。

　　关联规则挖掘所花费的时间主要是在生成频繁项集上，因为找出的频繁项集往往不会很多，利用频繁项集生成规则也就不会花太多的时间，而生成频繁项集需要测试很多的备选项集，如果不加优化，所需的时间是**O(2^N)**。



# **3、Apriori定律**

　　为了减少频繁项集的生成时间，我们应该尽早的消除一些完全不可能是频繁项集的集合，Apriori的两条定律就是干这事的。

　　Apriori定律1)：*如果一个集合是频繁项集，则它的所有子集都是频繁项集*。举例：假设一个集合{A,B}是频繁项集，即A、B同时出现在一条记录的次数大于等于最小支持度min_support，则它的子集{A},{B}出现次数必定大于等于min_support，即它的子集都是频繁项集。

　　Apriori定律2)：*如果一个集合不是频繁项集，则它的所有超集都不是频繁项集。*举例：假设集合{A}不是频繁项集，即A出现的次数小于min_support，则它的任何超集如{A,B}出现的次数必定小于min_support，因此其超集必定也不是频繁项集。

　　利用这两条定律，我们抛掉很多的候选项集，Apriori算法就是利用这两个定理来实现快速挖掘频繁项集的。

# **4、Apriori算法**

　　Apriori是由a priori合并而来的，它的意思是后面的是在前面的基础上推出来的，即先验推导，怎么个先验法，其实就是二级频繁项集是在一级频繁项集的基础上产生的，三级频繁项集是在二级频繁项集的基础上产生的，以此类推。

　　Apriori算法属于**候选消除算法，是一个生成候选集、消除不满足条件的候选集**、并不断循环直到不再产生候选集的过程。

　　![img](https://images0.cnblogs.com/blog/431880/201307/31160727-a7d9a4d0a64a4f4b83a831980273450d.jpg)

　　上面的图演示了Apriori算法的过程，注意看由二级频繁项集生成三级候选项集时，没有{牛奶,面包,啤酒}，那是因为{面包,啤酒}不是二级频繁项集，这里利用了Apriori定理。最后生成三级频繁项集后，没有更高一级的候选项集，因此整个算法结束，{牛奶,面包,尿布}是最大频繁子集。



# 5.FpGrowth算法

Aprori算法利用频繁集的两个特性，过滤了很多无关的集合，效率提高不少，但是我们发现Apriori算法是一个候选消除算法，每一次消除都需要扫描一次所有数据记录，造成整个算法在面临大数据集时显得无能为力。今天我们介绍一个新的算法挖掘频繁项集，效率比Aprori算法高很多。

　　FpGrowth算法通过构造一个树结构来压缩数据记录，使得挖掘频繁项集**只需要扫描两次数据记录**，而且该算法不需要生成候选集合，所以效率会比较高。我们还是以上一篇中用的数据集为例： 

| TID  | Items                 |
| ---- | --------------------- |
| T1   | {牛奶,面包}           |
| T2   | {面包,尿布,啤酒,鸡蛋} |
| T3   | {牛奶,尿布,啤酒,可乐} |
| T4   | {面包,牛奶,尿布,啤酒} |
| T5   | {面包,牛奶,尿布,可乐} |

## **5.1、构造FpTree**

　　FpTree是一种树结构，树结构定义如下： 

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
public class FpNode {

    String idName;// id号
    List<FpNode> children;// 孩子结点
    FpNode parent;// 父结点
    FpNode next;// 下一个id号相同的结点
    long count;// 出现次数
} 
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

　　树的每一个结点代表一个项，这里我们先不着急看树的结构，我们演示一下FpTree的构造过程，FpTree构造好后自然明白了树的结构。假设我们的最小绝对支持度是3。

　　**Step 1：**扫描数据记录，**生成一级频繁项集**，并按出现次数由多到少排序，如下所示： 

| Item | Count |
| ---- | ----- |
| 牛奶 | 4     |
| 面包 | 4     |
| 尿布 | 4     |
| 啤酒 | 3     |

　　可以看到，鸡蛋和可乐没有出现在上表中，因为可乐只出现2次，鸡蛋只出现1次，小于最小支持度，因此不是频繁项集，根据Apriori定理，非频繁项集的超集一定不是频繁项集，所以可乐和鸡蛋不需要再考虑。

　　**Step 2：**再次扫描数据记录，对每条记录中出现在Step 1产生的表中的项，按表中的顺序排序。初始时，新建一个根结点，标记为null；

　　**1）**第一条记录：{牛奶,面包}，按Step 1表过滤排序得到依然为{牛奶,面包}，新建一个结点，idName为{牛奶}，将其插入到根节点下，并设置count为1，然后新建一个{面包}结点，插入到{牛奶}结点下面，插入后如下所示：

![img](https://images0.cnblogs.com/blog/431880/201308/05213701-8bf8c8750dee440dbb110e6e514e8c74.jpg)

　　**2）**第二条记录：{面包,尿布,啤酒,鸡蛋}，过滤并排序后为：{面包,尿布,啤酒}，发现根结点没有包含{面包}的儿子（有一个{面包}孙子但不是儿子），因此新建一个{面包}结点，插在根结点下面，这样根结点就有了两个孩子，随后新建{尿布}结点插在{面包}结点下面，新建{啤酒}结点插在{尿布}下面，插入后如下所示：

 ![img](https://images0.cnblogs.com/blog/431880/201308/05213458-5fd67fd628434e1d936b3e58c907ce0b.jpg)

　　**3）**第三条记录：{牛奶,尿布,啤酒,可乐}，过滤并排序后为：{牛奶,尿布,啤酒}，这时候发现根结点有儿子{牛奶}，因此不需要新建结点，只需将原来的{牛奶}结点的count加1即可，往下发现{牛奶}结点有一个儿子{尿布}，于是新建{尿布}结点，并插入到{牛奶}结点下面，随后新建{啤酒}结点插入到{尿布}结点后面。插入后如下图所示：

![img](https://images0.cnblogs.com/blog/431880/201308/05214534-13b227b9dbb44d2983cc8406ff6e8588.jpg)

　　**4）**第四条记录：{面包,牛奶,尿布,啤酒}，过滤并排序后为：{牛奶，面包,尿布,啤酒}，这时候发现根结点有儿子{牛奶}，因此不需要新建结点，只需将原来的{牛奶}结点的count加1即可，往下发现{牛奶}结点有一个儿子{面包}，于是也不需要新建{面包}结点，只需将原来{面包}结点的count加1，由于这个{面包}结点没有儿子，此时需新建{尿布}结点，插在{面包}结点下面，随后新建{啤酒}结点，插在{尿布}结点下面，插入后如下图所示：

　　![img](https://images0.cnblogs.com/blog/431880/201308/05214830-a9ce3707d5ae484885142ff5e8ded5bf.jpg)

 

　　**5）**第五条记录：{面包,牛奶,尿布,可乐}，过滤并排序后为：{牛奶，面包,尿布}，检查发现根结点有{牛奶}儿子，{牛奶}结点有{面包}儿子，{面包}结点有{尿布}儿子，本次插入不需要新建结点只需更新count即可，示意图如下：

　　![img](https://images0.cnblogs.com/blog/431880/201308/05215333-9e3232d0a81d46898ac058c9bcd4d002.jpg)

 

　　按照上面的步骤，我们已经基本构造了一棵FpTree（Frequent Pattern Tree），树中每天路径代表一个项集，因为许多项集有公共项，而且出现次数越多的项越可能是公公项，因此按出现次数由多到少的顺序可以节省空间，实现压缩存储，另外我们需要一个表头和对每一个idName相同的结点做一个线索，方便后面使用，线索的构造也是在建树过程形成的，但为了简化FpTree的生成过程，我没有在上面提到，这个在代码有体现的，添加线索和表头的Fptree如下：

![img](https://images0.cnblogs.com/blog/431880/201308/06083215-3a6581c951614c1d82d434bc9d9383d0.jpg)

　　至此，整个FpTree就构造好了，在下面的挖掘过程中我们会看到表头和线索的作用。

## **5.2、利用FpTree挖掘频繁项集**

 　FpTree建好后，就可以进行频繁项集的挖掘，挖掘算法称为FpGrowth（Frequent Pattern Growth）算法，挖掘从表头header的最后一个项开始。

　　**1）**此处即从{啤酒}开始，根据{啤酒}的线索链找到所有{啤酒}结点，然后找出每个{啤酒}结点的分支：{牛奶，面包，尿布，啤酒：1}，{牛奶，尿布，啤酒:1}，{面包，尿布，啤酒:1}，其中的“1”表示出现1次，注意，虽然{牛奶}出现4次，但{牛奶，面包，尿布，啤酒}只同时出现1次，因此分支的count是由后缀结点{啤酒}的count决定的，除去{啤酒}，我们得到对应的前缀路径{牛奶，面包，尿布：1}，{牛奶，尿布:1}，{面包，尿布:1}，根据前缀路径我们可以生成一颗条件FpTree，构造方式跟之前一样，此处的数据记录变为：

| TID  | Items              |
| ---- | ------------------ |
| T1   | {牛奶，面包，尿布} |
| T2   | {牛奶，尿布}       |
| T3   | {面包，尿布}       |

　　绝对支持度依然是3，构造得到的FpTree为：

![img](https://images0.cnblogs.com/blog/431880/201308/06091610-fcfd109d4baf4bbc953d450132c7425c.jpg)

构造好条件树后，对条件树进行递归挖掘，当条件树只有一条路径时，路径的所有组合即为条件频繁集，假设{啤酒}的条件频繁集为{S1,S2,S3}，则{啤酒}的频繁集为{S1+{啤酒},S2+{啤酒},S3+{啤酒}}，即{啤酒}的频繁集一定有相同的后缀{啤酒}，此处的条件频繁集为：{{}，{尿布}}，于是{啤酒}的频繁集为{{啤酒}{尿布，啤酒}}。

　　**2）**接下来找header表头的倒数第二个项{尿布}的频繁集，同上可以得到{尿布}的前缀路径为：{面包：1}，{牛奶：1}，{牛奶，面包：2}，条件FpTree的数据集为：

| TID  | Items        |
| ---- | ------------ |
| T1   | {面包}       |
| T2   | {牛奶}       |
| T3   | {牛奶，面包} |
| T4   | {牛奶，面包} |

　　注意{牛奶，面包：2}，即{牛奶，面包}的count为2，所以在{牛奶，面包}重复了两次，这样做的目的是可以利用之前构造FpTree的算法来构造条件Fptree，不过这样效率会降低，试想如果{牛奶，面包}的count为20000，那么就需要展开成20000条记录，然后进行20000次count更新，而事实上只需要对count更新一次到20000即可。这是实现上的优化细节，实践中当注意。构造的条件FpTree为：

![img](https://images0.cnblogs.com/blog/431880/201308/06095928-e1d88d1ede204f3d949b7153287cd992.jpg)
 　这颗条件树已经是单一路径，路径上的所有组合即为条件频繁集：{{}，{牛奶}，{面包}，{牛奶，面包}}，加上{尿布}后，又得到一组频繁项集{{尿布}，{牛奶，尿布}，{面包，尿布}，{牛奶，面包，尿布}}，这组频繁项集一定包含一个相同的后缀：{尿布}，并且不包含{啤酒}，因此这一组频繁项集与上一组不会重复。

　　重复以上步骤，对header表头的每个项进行挖掘，即可得到整个频繁项集，可以证明（严谨的算法和证明可见参考文献[1]），频繁项集即不重复也不遗漏。